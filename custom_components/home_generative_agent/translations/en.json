{
  "config": {
    "error": {
      "cannot_connect": "Failed to connect",
      "invalid_auth": "Invalid authentication",
      "unknown": "Unexpected error"
    },
    "step": {
      "user": {
        "data": {
          "api_key": "API key"
        }
      }
    }
  },
  "exceptions": {
    "invalid_config_entry": {
      "message": "Invalid config entry provided. Got {config_entry}"
    }
  },
  "options": {
    "step": {
      "init": {
        "data": {
          "prompt": "Instructions",
          "chat_model_location": "Chat model location",
          "chat_model": "Chat model",
          "chat_model_temperature": "Chat model temperature",
          "edge_chat_model": "Edge chat model",
          "edge_chat_model_temperature": "Edge chat model temperature",
          "edge_chat_model_top_p": "Edge chat model top P",
          "vlm": "VLM",
          "vlm_temperature": "VLM temperature",
          "vlm_top_p": "VLM top P",
          "summarization_model": "Summarization model",
          "summarization_model_temperature": "Summarization model temperature",
          "summarization_model_top_p": "Summarization model top P",
          "embedding_model": "Embedding model",
          "llm_hass_api": "Control Home Assistant",
          "recommended": "Recommended model settings",
          "video_analyzer_mode": "Video analyzer mode"
        },
        "data_description": {
          "prompt": "Instruct how the LLM should respond. This can be a template."
        }
      }
    }
  }
}